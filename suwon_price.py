# -*- coding: utf-8 -*-
"""suwon_price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OYzI03v6sHsqs624P5qWZz8Ru48-qlE3

# 라이브러리 호출
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib as mpl
import plotly.express as px
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.model_selection import *
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import AdaBoostRegressor
from xgboost import XGBRegressor
import numpy as np
import platform

"""# 한글 폰트 설치"""

# 단계 1: 폰트 설치

!apt-get -qq -y install fonts-nanum > /dev/null
font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'

font_name = fm.FontProperties(fname=font_path, size=9).get_name()

#fm._rebuild()

fe = fm.FontEntry(
    fname=r'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf', # ttf 파일이 저장되어 있는 경로
    name='NanumGothic')                        # 이 폰트의 원하는 이름 설정
fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가
plt.rcParams.update({'font.size': 18, 'font.family': 'NanumGothic'}) # 폰트 설

"""# 데이터 호출 및 전처리"""

# JSON 파일을 읽어서 데이터 프레임으로 변환
df_20220228 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20220228_suwon_pride_trend")
df_20220324 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20220324_suwon_pride_trend")
df_20220424 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20220424_suwon_pride_trend")
df_20220524 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20220524_suwon_pride_trend")
df_20220624 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20220624_suwon_pride_trend")
df_20220724 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20220724_suwon_pride_trend")
df_20220824 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20220824_suwon_pride_trend")
df_20220926 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20220926_suwon_pride_trend")
df_20221024 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20221024_suwon_pride_trend")
df_20221125 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20221125_suwon_pride_trend")
df_20221227 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20221227_suwon_pride_trend")
df_20220125 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20230125_suwon_pride_trend")
df_20230228 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20230228_suwon_pride_trend")
df_20230328 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20230328_suwon_pride_trend")
df_20230428 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20230428_suwon_pride_trend")
df_20230526 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20230526_suwon_pride_trend")
df_20230626 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20230626_suwon_pride_trend")
df_20230726 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/c88497cfd2fe881fa08c0850b94311da0f555eab/20230726_suwon_pride_trend")
df_20230825 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20230825_suwon_pride_trend")
df_20230926 = pd.read_json("https://gist.githubusercontent.com/chanho0908/f638455cd0874917692b02d8a9548378/raw/6369d0e9abb6fa0cd3ccef7550b177690b17831f/20230926_suwon_pride_trend")

# 데이터 프레임 리스트
dfs = [
    df_20220228, df_20220324, df_20220424, df_20220524, df_20220624, df_20220724, df_20220824, df_20220926, df_20221024, df_20221125,
    df_20221227, df_20220125, df_20230228, df_20230328, df_20230428, df_20230526, df_20230626, df_20230726, df_20230825, df_20230926
]

# 데이터 프레임 합치기
firstDataFrame = pd.concat(dfs, ignore_index=True)

# 필요없는 열 삭제
firstDataFrame.drop(['데이터기준일자', '규격 및 단위'], axis=1, inplace=True)

# Json에서 값이 ""일 경우 판다스는 누락된 값이 아닌 빈 문자열로 처리
# 물가동향 열에서 빈 문자열을 NaN으로 변환
firstDataFrame['물가동향'].replace('', pd.NA, inplace=True)

# 숫자로 변환이 불가능한 값은 NaN으로 처리
firstDataFrame['물가동향'] = pd.to_numeric(firstDataFrame['물가동향'], errors='coerce')

# NaN 값을 가진 행을 삭제
df_natnan = firstDataFrame.dropna(subset=['물가동향'])

# 물가 동향의 값이 빈 경우 확인
no_values_count = df_natnan['물가동향'].isna().sum()
#print('물가 동향의 값이 비어있는 경우: ', no_values_count)

# 물가 동향의 값이 데이터 미존재인 경우 확인
noData = (df_natnan['물가동향'] == '데이터미존재').sum()
#print('물가 동향의 값이 데이터미존재인 경우: ', noData)

# '기준일' 열을 datetime 형식으로 변환
df_natnan['기준일'] = pd.to_datetime(df_natnan['기준일'])

# '기준일' 열을 월까지만 보여줌
df_natnan['기준일'] = df_natnan['기준일'].dt.strftime('%Y-%m')

'''
현재 데이터는 한 달 동안 한 가지 품목의 물가에 대해서 날짜에 따라 여러번 작성됨
한 달 동안 가장 높은 가격을 기록한 날만 남기고 나머지 데이터는 삭제
'''

# 데이터프레임을 '기준일', '품목' 및 '물가동향' 열을 기준으로 그룹화
# 각 그룹에 대해 '물가동향' 열에서 최대 값을 가지는 행을 선택
grouped_df = df_natnan.groupby(['기준일', '품목'])['물가동향'].idxmax()

# 선택한 행의 인덱스를 사용하여 원래 데이터프레임에서 해당 행을 추출하여 새로운 데이터프레임을 생성
mainDataFrame = df_natnan.loc[grouped_df]

#삭제된 행 확인
#deleted_rows = mainDataFrame[~mainDataFrame.index.isin(filtered_df.index)]
#deleted_rows

mainDataFrame

"""# 한식 데이터 분석"""

# 한식만 추출
korean_food = mainDataFrame[mainDataFrame['구분'].str.contains('한식')].copy()
k_food_list = korean_food['품목'].drop_duplicates().tolist()
df_kfood = mainDataFrame[mainDataFrame['품목'].isin(k_food_list)]

# DataFrame을 '품목' 컬럼으로 그룹핑 하고, '물가동향' 컬럼에 12개월(12개월, 즉 1년을 나타냄)
# 로 df_kfood 변화율( ) 함수를 적용하여 전년 대비 인플레이션을 계산
df_kfood['전년동월대비'] = df_kfood.groupby('품목')['물가동향'].pct_change(periods=12)
df_kfood.dropna(inplace=True)

# 그래프 그리기
fig = px.bar(
    df_kfood,
    x='전년동월대비',
    y='품목',
    text='전년동월대비',
    orientation='h',
    color='품목',
    color_discrete_sequence=px.colors.qualitative.Set3,
    hover_data=['기준일']  # Add '기준일' to hover data
)

fig.update_traces(
    texttemplate='%{text:.1%}',
    textposition='outside',  # 텍스트 형식 및 위치 설정
    hovertemplate='월: %{customdata[0]}<br>전년동월대비: %{x:.1%}<extra></extra>'  # Custom hover template
)

# 그래프 크기 조절
fig.update_layout(
    title=dict(
        text='한식 전월 동원 대비 물가 상승률',
        x=0.5,  # Center the title
        y=0.95,  # Adjust the vertical position of the title
        xanchor='center',
        yanchor='top',
    ),
    width=1300,
    height=600
)

fig.show()

"""# 소고기 물가 상승률"""

df_beef = mainDataFrame[mainDataFrame['품목'] == '쇠고기']
df_beef = df_beef[df_beef['기준일'].str.contains('2023')]
df_beef['전년동월대비'] = df_beef['물가동향']
#df_beef.dropna(inplace=True)

# 시각화
plt.figure(figsize=(18, 6))

# 물가 동향 선 그래프
ax = sns.lineplot(data=df_beef, x='기준일', y='물가동향', marker='o', label='물가 동향')

# 그래프 타이틀 및 레이블 설정
plt.title('소고기 물가 상승률', fontsize=18)
plt.xlabel('기준일', fontsize=14)
plt.ylabel('물가 동향', fontsize=14)

#각 데이터 포인트에 숫자로 된 라벨 추가
for i, txt in enumerate(df_beef['전년동월대비']):
   ax.text(df_beef['기준일'].iloc[i], df_beef['물가동향'].iloc[i], txt, ha='center', va='bottom')

# 그래프 표시
plt.show()

"""# 소고기를 사용하는 음식 물가 분석"""

df_beef = mainDataFrame[mainDataFrame['품목'] == '쇠고기']
df_use_beef_items = ['갈비탕', '불고기', '설렁탕']

# 품목이 df_use_beef_items에 있는 데이터만 필터링
df_selected_beef_items = mainDataFrame[mainDataFrame['품목'].isin(df_use_beef_items)].copy()

# 전년동월대비 물가 상승률 계산
df_selected_beef_items['전년동월대비'] = df_selected_beef_items.groupby('품목')['물가동향'].pct_change(periods=12)
df_selected_beef_items.dropna(inplace=True)

colors = sns.color_palette("husl", len(df_use_beef_items))
# 그래프 그리기 - subplot으로 나눠서 표시
fig, axes = plt.subplots(3, 1, figsize=(8, 13))  # One row, three columns

# Iterate through each item and plot it on a separate subplot
for i, (item, color) in enumerate(zip(df_use_beef_items, colors)):
    # Check if the data for the item is not empty before creating the line plot
    if not df_selected_beef_items[df_selected_beef_items['품목'] == item].empty:
        sns.lineplot(data=df_selected_beef_items[df_selected_beef_items['품목'] == item],
                     x='기준일', y='전년동월대비', ax=axes[i], color=color, marker='o', label=item)
        axes[i].set_title(item)
        axes[i].set_xlabel('기준일')
        axes[i].set_ylabel('전년동월대비 물가 상승률')
        axes[i].legend()

# Adjust layout
plt.tight_layout()

# Show the plot
plt.show()

"""# 수산물 전월 대비 물가 동향"""

df_seafood = mainDataFrame[mainDataFrame['구분'].str.contains('수산물')].copy()
seafood_list = df_seafood['품목'].drop_duplicates().tolist()
seafood = mainDataFrame[mainDataFrame['품목'].isin(seafood_list)]

# '품목'을 기준으로 그룹화하고 '물가동향' 열에서 전년동월대비 물가 상승 지수 계산
df_seafood['전년동월대비'] = df_seafood.groupby('품목')['물가동향'].pct_change(periods=12)
df_seafood.dropna(inplace=True)

# 결과 확인
# '고등어' 품목 선택
df_mackerel = df_seafood[df_seafood['품목'] == '고등어']
# '갈치' 품목 선택
df_cutlassfish = df_seafood[df_seafood['품목'] == '갈치']
# '동태' 품목 선택
df_dongtae = df_seafood[df_seafood['품목'] == '동태']
# '오징어' 품목 선택
df_squid = df_seafood[df_seafood['품목'] == '오징어']

# 그래프 그리기
plt.figure(figsize=(15, 7))
plt.plot(df_mackerel['기준일'], df_mackerel['전년동월대비'], label='고등어', marker='o', linestyle='-')
plt.plot(df_cutlassfish['기준일'], df_cutlassfish['전년동월대비'], label='갈치', marker='o', linestyle='-')
plt.plot(df_dongtae['기준일'], df_dongtae['전년동월대비'], label='동태', marker='o', linestyle='-')
plt.plot(df_squid['기준일'], df_squid['전년동월대비'], label='오징어', marker='o', linestyle='-')

# 차트에 전년동월대비가 가장 높은 지점에 해당하는 값을 추가
max_value = df_seafood.loc[df_seafood['전년동월대비'].idxmax()]
plt.annotate(f'Max: {max_value["전년동월대비"]*0.01:.2%}\n{max_value["기준일"]}',
             xy=(max_value['기준일'], max_value['전년동월대비']),
             xytext=(max_value['기준일'], max_value['전년동월대비'] + 0.1),  # 위치 조정
             arrowprops=dict(facecolor='red', shrink=0.05),  # 화살표 추가
             )

# Marker 위에 값 표시 (최소값)
for i, txt in enumerate(df_seafood[df_seafood['전년동월대비'] == df_seafood['전년동월대비'].min()]['전년동월대비']):
    plt.text(df_seafood[df_seafood['전년동월대비'] == df_seafood['전년동월대비'].min()]['기준일'].iloc[i],
             txt + 0.05, f'Min: {txt*0.01:.2%}', ha='center', va='bottom', color='green')

plt.title('수산물 전년동월대비 물가 동향(%)', loc='left', fontsize=20)
plt.xlabel('기준일')
plt.ylabel('전년동월대비')
plt.xticks(rotation=45)
plt.grid(True)
plt.legend()
plt.tight_layout()

# 그래프 표시
plt.show()

"""# 치킨 데이터 분석"""

# 치킨 데이터만 분리
df_chicken = mainDataFrame[mainDataFrame['품목'] == '치킨'].copy()

# 전년도 동월 가격과 비교
df_chicken['전년동월대비'] = df_chicken['물가동향'].pct_change(periods=12)
df_chicken.dropna(inplace=True)

# 시각화할 데이터만 분리
df_chicken = df_chicken[['기준일', '전년동월대비']]

fig = px.bar(df_chicken, x='기준일', y='전년동월대비', color='기준일',
             color_continuous_scale=px.colors.sequential.Oranges,
             title='전년 동월 대비 치킨 상승률',
             )
fig.update_layout(width=900)
'''
데이터프레임의 각 행을 반복하면서 플롯에 주석을 추가
  x : 주석의 x 좌표
  y : 주석의 y 좌표
  showarrow : 화살표 표시
  arrowhead : 화살표 머리
'''
for i, row in df_chicken.iterrows():
    fig.add_annotation(
        x=row['기준일'],
        y=row['전년동월대비'],
        text=f"{row['전년동월대비']:.2%}",
        showarrow=True,
        arrowhead=2,
        arrowcolor="black",
    )

# 제목 가운데로 옮기기
fig.update_layout(
    title=dict(
        text='전년 동월 대비 치킨 상승률',
        x=0.5,
        font=dict(size=24)  # font size 설정
    )
)

fig.update_xaxes(type='category')
fig.show()

"""# 회귀 알고리즘을 사용한 치킨 물가 예측"""

# 데이터 분리
reg_df_chicken = mainDataFrame[mainDataFrame['품목'] == '치킨'].copy()
reg_df_chicken = reg_df_chicken[['기준일', '물가동향']]
reg_df_chicken['기준일'] = pd.to_datetime(reg_df_chicken['기준일'])
reg_df_chicken['Month'] = reg_df_chicken['기준일'].dt.month
reg_df_chicken = reg_df_chicken[['Month', '물가동향']]
reg_df_chicken

def get_model_cv_prediction(model, X_data, y_target):
    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring="neg_mean_squared_error", cv=7)
    rmse_scores = np.sqrt(-1 * neg_mse_scores)
    avg_rmse = np.mean(rmse_scores)
    print('##### ', model.__class__.__name__, ' #####')
    print(' 7 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))

def get_cv_predictions(model, X_data, y_target):
    predicted = cross_val_predict(model, X_data, y_target, cv=7)
    return predicted

y_target = reg_df_chicken['물가동향']
X_data = reg_df_chicken[['Month']]

X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.3, random_state=42)

ada_reg = AdaBoostRegressor()
xgb_reg = XGBRegressor()

# 트리 기반의 회귀 모델을 반복하면서 평가 수행
models = [ada_reg, xgb_reg]
for model in models:
    get_model_cv_prediction(model, X_data, y_target)

# 데이터 학습
ada_reg.fit(X_train, y_train)
xgb_reg.fit(X_train, y_train)

ada_pred_cv = get_cv_predictions(ada_reg, X_data, y_target)
xgb_pred_cv = get_cv_predictions(xgb_reg, X_data, y_target)

results_df_cv = pd.DataFrame({
    'Actual': y_target,
    'AdaBoost Predicted (CV)': ada_pred_cv,
    'XGBoost Predicted (CV)': xgb_pred_cv,
    'Month': reg_df_chicken['Month'].astype(str)
})

# 시각화
sns.set(color_codes=True)

plt.figure(figsize=(16, 6))

for i, model_name in enumerate(['AdaBoost', 'XGBoost']):
    plt.subplot(1, 2, i+1)
    sns.lineplot(x='Month', y='Actual', data=results_df_cv, label='DATA', linewidth=2.5)
    sns.lineplot(x='Month', y=f'{model_name} Predicted (CV)', data=results_df_cv, label='PREDICT', linewidth=2.5)
    plt.title(model_name)
    plt.xlabel('Month')
    plt.ylabel('Price')
    plt.legend()

plt.tight_layout()
plt.show()

"""# MODEL : DecisionTreeRegressor"""

# 데이터 전처리
df_chicken = mainDataFrame[mainDataFrame['품목'] == '치킨'].copy()
df_chicken['기준일'] = pd.to_datetime(df_chicken['기준일'])
df_chicken = df_chicken.sort_values('기준일')

# 특성 선택
X = df_chicken['기준일'].dt.month.values.reshape(-1, 1)
y = df_chicken['물가동향'].values

# 훈련 및 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)

# 결정 트리 모델 학습
model = DecisionTreeRegressor(max_depth=10)
model.fit(X_train, y_train)

# 테스트 데이터에 대한 예측
y_pred = model.predict(X_test)

# 평가
mse = mean_squared_error(y_test, y_pred)
# RMSE 계산 및 출력
rmse = np.sqrt(mse)
print(f'Root Mean Squared Error (RMSE): {rmse}')

# 예측 결과 시각화
plt.figure(figsize=(17, 6))
plt.scatter(df_chicken['기준일'], df_chicken['물가동향'], label='DATA')
plt.plot(df_chicken['기준일'], model.predict(X), color='red', label='PREDICT')
plt.xlabel('MONTH')
plt.ylabel('PRICE')
plt.legend()
plt.show()

"""# MODEL : LinearRegression(선형 회귀)"""

# 데이터 전처리
df_chicken = mainDataFrame[mainDataFrame['품목'] == '치킨'].copy()
df_chicken['기준일'] = pd.to_datetime(df_chicken['기준일'])
df_chicken = df_chicken.sort_values('기준일')

# 특성 선택
X = df_chicken['기준일'].dt.month.values.reshape(-1, 1)
y = df_chicken['물가동향'].values

# 훈련 및 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)

# 회귀 모델 학습
model = LinearRegression()
model.fit(X_train, y_train)

# 테스트 데이터에 대한 예측
y_pred = model.predict(X_test)

# 평가
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print(f'Root Mean Squared Error (RMSE) on Test Set: {rmse}')

# 예측 결과 시각화
plt.figure(figsize=(17, 6))
plt.scatter(df_chicken['기준일'], df_chicken['물가동향'], label='DATA')
plt.plot(df_chicken['기준일'], model.predict(X), color='red', label='PREDICT')
plt.xlabel('Month')
plt.ylabel('PRICE')
plt.legend()
plt.show()

"""# 네이버 API 크롤링"""

# import os
# import sys
# import urllib.request
# import datetime
# import time
# import json

# client_id = '0LHQM4VX_MQM6JfkXofa'
# client_secret = 'OcPgqpswCg'


# #[CODE 1]
# #1. 검색어 지정
# def getRequestUrl(url):
#   req = urllib.request.Request(url) # 매개변수로 받은 url에 대한 요청을 보낼 객체를 생성
#   req.add_header("X-Naver-Client-Id", client_id) # API를 사용하기 위한 Client ID와 Client Secret 코드를 요청 객체 헤드에 추가
#   req.add_header("X-Naver-Client-Secret", client_secret)

#   try:
#       response = urllib.request.urlopen(req) # 요청 객체를 보내고 그에 대한 응답을 받아 response 객체에 저장
#       if response.getcode() == 200: # 정상 처리
#           print ("[%s] Url Request Success" % datetime.datetime.now()) # 정상 처리 메시지 출력
#           return response.read().decode('utf-8') # utf-8 형식으로 디코딩 후 반환
#   except Exception as e:
#       print(e)
#       print("[%s] Error for URL : %s" % (datetime.datetime.now(), url))
#       return None

# # 2. 네이버 뉴스 검색
#     #[CODE 2]
# def getNaverSearch(node, srcText, start, display):
#   base = "https://openapi.naver.com/v1/search"
#   node = "/%s.json" % node
#   parameters = "?query=%s&start=%s&display=%s" % (urllib.parse.quote(srcText), start, display)

#   url = base + node + parameters # 네이버 검색 API 정보에 따라 요청 URL을 구성
#   responseDecode = getRequestUrl(url)   #[CODE 1]

#   if (responseDecode == None):
#       return None
#   else:
#       return json.loads(responseDecode) # 서버에서 받은 JSON 형태의 응답 객체를 파이썬 객체로 로드하여 반환

# #[CODE 3]
# def getPostData(post, jsonResult, cnt):
#     title = post['title']
#     description = post['description']
#     org_link = post['originallink']
#     link = post['link']

#     pDate = datetime.datetime.strptime(post['pubDate'],  '%a, %d %b %Y %H:%M:%S +0900')
#     pDate = pDate.strftime('%Y-%m-%d %H:%M:%S')

#     jsonResult.append({'cnt':cnt, 'title':title, 'description': description,
# 'org_link':org_link,   'link': org_link,   'pDate':pDate})
#     return

# #[CODE 0]
# def main():
#     node = 'news'   # 크롤링 할 대상
#     srcText = input('검색어를 입력하세요: ')
#     cnt = 0
#     jsonResult = []

#     jsonResponse = getNaverSearch(node, srcText, 1, 100)  #[CODE 2]
#     total = jsonResponse['total']

#     while ((jsonResponse != None) and (jsonResponse['display'] != 0)):
#         for post in jsonResponse['items']:
#             cnt += 1
#             getPostData(post, jsonResult, cnt)  #[CODE 3]

#         start = jsonResponse['start'] + jsonResponse['display']
#         jsonResponse = getNaverSearch(node, srcText, start, 100)  #[CODE 2]

#     print('전체 검색 : %d 건' %total)

#     with open('%s_naver_%s.json' % (srcText, node), 'w', encoding='utf8') as outfile:
#         jsonFile = json.dumps(jsonResult,  indent=4, sort_keys=True,  ensure_ascii=False)

#         outfile.write(jsonFile)

#     print("가져온 데이터 : %d 건" %(cnt))
#     print ('%s_naver_%s.json SAVED' % (srcText, node))

# if __name__ == '__main__':
#     main()

df_crawling = pd.read_json('/content/치킨 물가_naver_news.json')
df_crawling = df_crawling.drop(['link', 'org_link'], axis=1)
df_crawling.head()

"""# 워드 클라우딩

## KoNLPy library 설치
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# apt-get update
# apt-get install g++ openjdk-8-jdk pythondev
# python3-dev
# pip3 install JPype1
# pip3 install konlpy

"""## 라이브러리 import"""

import json
import re

from konlpy.tag import Okt
from PIL import Image
from collections import Counter

import matplotlib
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc
from wordcloud import WordCloud

"""## 파일 읽기"""

inputFileName = '/content/수원시 물가_naver_news'
data = json.loads(open(inputFileName+'.json', 'r', encoding='utf-8').read())
data #출력하여 내용 확인

"""## 분석 데이터 추출"""

message = ''

for item in data:
    if 'description' in item.keys():
        message = message + re.sub(r'[^\w]', ' ', item['description']) +''

message #출력하여 내용 확인

"""## 품사 태깅 : 명사 추출"""

nlp = Okt()
message_N = nlp.nouns(message)
message_N   #출력하여 내용 확인

"""## 단어 빈도 탐색"""

count = Counter(message_N)

count   #출력하여 내용 확인

word_count = dict()

for tag, counts in count.most_common(80):
    if(len(str(tag))>1):
        word_count[tag] = counts
        print("%s : %d" % (tag, counts))

mask_path = 'cloud.png'
cloud_mask = np.array(Image.open(mask_path)) # 구름 모양 워드 클라우드 생성

wc = WordCloud(font_path, background_color='white', width=800, height=600, mask=cloud_mask, colormap='inferno')
cloud=wc.generate_from_frequencies(word_count)

plt.figure(figsize=(8,8))
plt.imshow(cloud)
plt.axis('off')
plt.show()